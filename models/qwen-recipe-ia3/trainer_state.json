{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3564,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.042105263157894736,
      "grad_norm": 0.5659071207046509,
      "learning_rate": 0.000245,
      "loss": 2.9463,
      "step": 50
    },
    {
      "epoch": 0.08421052631578947,
      "grad_norm": 0.253368079662323,
      "learning_rate": 0.000495,
      "loss": 2.7534,
      "step": 100
    },
    {
      "epoch": 0.12631578947368421,
      "grad_norm": 0.2344798892736435,
      "learning_rate": 0.0004929272517321016,
      "loss": 2.541,
      "step": 150
    },
    {
      "epoch": 0.16842105263157894,
      "grad_norm": 0.21513447165489197,
      "learning_rate": 0.00048571016166281756,
      "loss": 2.4601,
      "step": 200
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.21803998947143555,
      "learning_rate": 0.0004784930715935335,
      "loss": 2.4334,
      "step": 250
    },
    {
      "epoch": 0.25263157894736843,
      "grad_norm": 0.17363619804382324,
      "learning_rate": 0.00047127598152424947,
      "loss": 2.3944,
      "step": 300
    },
    {
      "epoch": 0.29473684210526313,
      "grad_norm": 0.2561606168746948,
      "learning_rate": 0.0004640588914549654,
      "loss": 2.3357,
      "step": 350
    },
    {
      "epoch": 0.3368421052631579,
      "grad_norm": 0.209138423204422,
      "learning_rate": 0.0004568418013856813,
      "loss": 2.3109,
      "step": 400
    },
    {
      "epoch": 0.37894736842105264,
      "grad_norm": 0.18279437720775604,
      "learning_rate": 0.00044962471131639725,
      "loss": 2.3066,
      "step": 450
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.18504458665847778,
      "learning_rate": 0.00044240762124711313,
      "loss": 2.2499,
      "step": 500
    },
    {
      "epoch": 0.4631578947368421,
      "grad_norm": 0.14897163212299347,
      "learning_rate": 0.0004351905311778291,
      "loss": 2.2864,
      "step": 550
    },
    {
      "epoch": 0.5052631578947369,
      "grad_norm": 0.1854860633611679,
      "learning_rate": 0.00042797344110854504,
      "loss": 2.2193,
      "step": 600
    },
    {
      "epoch": 0.5473684210526316,
      "grad_norm": 0.19139191508293152,
      "learning_rate": 0.00042075635103926097,
      "loss": 2.2528,
      "step": 650
    },
    {
      "epoch": 0.5894736842105263,
      "grad_norm": 0.18114398419857025,
      "learning_rate": 0.0004135392609699769,
      "loss": 2.2313,
      "step": 700
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.22313401103019714,
      "learning_rate": 0.0004063221709006928,
      "loss": 2.1983,
      "step": 750
    },
    {
      "epoch": 0.6736842105263158,
      "grad_norm": 0.15364083647727966,
      "learning_rate": 0.0003991050808314088,
      "loss": 2.2262,
      "step": 800
    },
    {
      "epoch": 0.7157894736842105,
      "grad_norm": 0.1978989988565445,
      "learning_rate": 0.00039188799076212474,
      "loss": 2.2234,
      "step": 850
    },
    {
      "epoch": 0.7578947368421053,
      "grad_norm": 0.16893497109413147,
      "learning_rate": 0.00038467090069284067,
      "loss": 2.2076,
      "step": 900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.15850438177585602,
      "learning_rate": 0.0003774538106235566,
      "loss": 2.1806,
      "step": 950
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.18285009264945984,
      "learning_rate": 0.0003702367205542725,
      "loss": 2.2242,
      "step": 1000
    },
    {
      "epoch": 0.8842105263157894,
      "grad_norm": 0.18674467504024506,
      "learning_rate": 0.0003630196304849885,
      "loss": 2.1786,
      "step": 1050
    },
    {
      "epoch": 0.9263157894736842,
      "grad_norm": 0.20116128027439117,
      "learning_rate": 0.0003558025404157044,
      "loss": 2.1594,
      "step": 1100
    },
    {
      "epoch": 0.968421052631579,
      "grad_norm": 0.17711018025875092,
      "learning_rate": 0.0003485854503464203,
      "loss": 2.1918,
      "step": 1150
    },
    {
      "epoch": 1.0101052631578948,
      "grad_norm": 0.1826682686805725,
      "learning_rate": 0.00034136836027713624,
      "loss": 2.1825,
      "step": 1200
    },
    {
      "epoch": 1.0522105263157895,
      "grad_norm": 0.14760176837444305,
      "learning_rate": 0.00033415127020785217,
      "loss": 2.1659,
      "step": 1250
    },
    {
      "epoch": 1.0943157894736841,
      "grad_norm": 0.18415090441703796,
      "learning_rate": 0.00032693418013856815,
      "loss": 2.1702,
      "step": 1300
    },
    {
      "epoch": 1.136421052631579,
      "grad_norm": 0.2081938236951828,
      "learning_rate": 0.0003197170900692841,
      "loss": 2.2236,
      "step": 1350
    },
    {
      "epoch": 1.1785263157894736,
      "grad_norm": 0.16149309277534485,
      "learning_rate": 0.0003125,
      "loss": 2.1604,
      "step": 1400
    },
    {
      "epoch": 1.2206315789473685,
      "grad_norm": 0.15916362404823303,
      "learning_rate": 0.00030528290993071594,
      "loss": 2.1569,
      "step": 1450
    },
    {
      "epoch": 1.2627368421052632,
      "grad_norm": 0.18555913865566254,
      "learning_rate": 0.00029806581986143186,
      "loss": 2.1142,
      "step": 1500
    },
    {
      "epoch": 1.304842105263158,
      "grad_norm": 0.1643766462802887,
      "learning_rate": 0.00029084872979214785,
      "loss": 2.1702,
      "step": 1550
    },
    {
      "epoch": 1.3469473684210527,
      "grad_norm": 0.17621345818042755,
      "learning_rate": 0.0002836316397228638,
      "loss": 2.1448,
      "step": 1600
    },
    {
      "epoch": 1.3890526315789473,
      "grad_norm": 0.22231735289096832,
      "learning_rate": 0.0002764145496535797,
      "loss": 2.1482,
      "step": 1650
    },
    {
      "epoch": 1.4311578947368422,
      "grad_norm": 0.15349438786506653,
      "learning_rate": 0.00026919745958429563,
      "loss": 2.129,
      "step": 1700
    },
    {
      "epoch": 1.4732631578947368,
      "grad_norm": 0.1582840532064438,
      "learning_rate": 0.0002619803695150115,
      "loss": 2.1737,
      "step": 1750
    },
    {
      "epoch": 1.5153684210526315,
      "grad_norm": 0.14516858756542206,
      "learning_rate": 0.0002547632794457275,
      "loss": 2.1553,
      "step": 1800
    },
    {
      "epoch": 1.5574736842105263,
      "grad_norm": 0.18931618332862854,
      "learning_rate": 0.0002475461893764434,
      "loss": 2.1209,
      "step": 1850
    },
    {
      "epoch": 1.5995789473684212,
      "grad_norm": 0.2121172398328781,
      "learning_rate": 0.00024032909930715935,
      "loss": 2.1342,
      "step": 1900
    },
    {
      "epoch": 1.6416842105263156,
      "grad_norm": 0.20405609905719757,
      "learning_rate": 0.00023311200923787528,
      "loss": 2.105,
      "step": 1950
    },
    {
      "epoch": 1.6837894736842105,
      "grad_norm": 0.18458451330661774,
      "learning_rate": 0.00022589491916859123,
      "loss": 2.1501,
      "step": 2000
    },
    {
      "epoch": 1.7258947368421054,
      "grad_norm": 0.21104568243026733,
      "learning_rate": 0.00021867782909930716,
      "loss": 2.1836,
      "step": 2050
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.17487011849880219,
      "learning_rate": 0.00021146073903002312,
      "loss": 2.132,
      "step": 2100
    },
    {
      "epoch": 1.8101052631578947,
      "grad_norm": 0.17347835004329681,
      "learning_rate": 0.00020424364896073905,
      "loss": 2.1181,
      "step": 2150
    },
    {
      "epoch": 1.8522105263157895,
      "grad_norm": 0.1653367429971695,
      "learning_rate": 0.00019702655889145495,
      "loss": 2.1709,
      "step": 2200
    },
    {
      "epoch": 1.8943157894736842,
      "grad_norm": 0.21824778616428375,
      "learning_rate": 0.0001898094688221709,
      "loss": 2.1166,
      "step": 2250
    },
    {
      "epoch": 1.9364210526315788,
      "grad_norm": 0.23477447032928467,
      "learning_rate": 0.00018259237875288683,
      "loss": 2.1085,
      "step": 2300
    },
    {
      "epoch": 1.9785263157894737,
      "grad_norm": 0.1689334362745285,
      "learning_rate": 0.0001753752886836028,
      "loss": 2.1612,
      "step": 2350
    },
    {
      "epoch": 2.0202105263157897,
      "grad_norm": 0.1902482956647873,
      "learning_rate": 0.00016815819861431872,
      "loss": 2.1568,
      "step": 2400
    },
    {
      "epoch": 2.062315789473684,
      "grad_norm": 0.1661718785762787,
      "learning_rate": 0.00016094110854503467,
      "loss": 2.1458,
      "step": 2450
    },
    {
      "epoch": 2.104421052631579,
      "grad_norm": 0.15736384689807892,
      "learning_rate": 0.00015372401847575057,
      "loss": 2.1028,
      "step": 2500
    },
    {
      "epoch": 2.146526315789474,
      "grad_norm": 0.18288297951221466,
      "learning_rate": 0.0001465069284064665,
      "loss": 2.1382,
      "step": 2550
    },
    {
      "epoch": 2.1886315789473683,
      "grad_norm": 0.16608808934688568,
      "learning_rate": 0.00013928983833718246,
      "loss": 2.1304,
      "step": 2600
    },
    {
      "epoch": 2.230736842105263,
      "grad_norm": 0.1721944510936737,
      "learning_rate": 0.00013207274826789839,
      "loss": 2.1344,
      "step": 2650
    },
    {
      "epoch": 2.272842105263158,
      "grad_norm": 0.19006457924842834,
      "learning_rate": 0.00012485565819861431,
      "loss": 2.1329,
      "step": 2700
    },
    {
      "epoch": 2.314947368421053,
      "grad_norm": 0.16308775544166565,
      "learning_rate": 0.00011763856812933026,
      "loss": 2.0974,
      "step": 2750
    },
    {
      "epoch": 2.3570526315789473,
      "grad_norm": 0.1885225772857666,
      "learning_rate": 0.0001104214780600462,
      "loss": 2.1251,
      "step": 2800
    },
    {
      "epoch": 2.399157894736842,
      "grad_norm": 0.20095907151699066,
      "learning_rate": 0.00010320438799076213,
      "loss": 2.1015,
      "step": 2850
    },
    {
      "epoch": 2.441263157894737,
      "grad_norm": 0.19175109267234802,
      "learning_rate": 9.598729792147806e-05,
      "loss": 2.1147,
      "step": 2900
    },
    {
      "epoch": 2.4833684210526314,
      "grad_norm": 0.18717560172080994,
      "learning_rate": 8.8770207852194e-05,
      "loss": 2.1156,
      "step": 2950
    },
    {
      "epoch": 2.5254736842105263,
      "grad_norm": 0.1586005836725235,
      "learning_rate": 8.155311778290993e-05,
      "loss": 2.1471,
      "step": 3000
    },
    {
      "epoch": 2.567578947368421,
      "grad_norm": 0.1548241227865219,
      "learning_rate": 7.433602771362587e-05,
      "loss": 2.1235,
      "step": 3050
    },
    {
      "epoch": 2.609684210526316,
      "grad_norm": 0.20405076444149017,
      "learning_rate": 6.711893764434181e-05,
      "loss": 2.0997,
      "step": 3100
    },
    {
      "epoch": 2.6517894736842105,
      "grad_norm": 0.20630565285682678,
      "learning_rate": 5.990184757505774e-05,
      "loss": 2.1234,
      "step": 3150
    },
    {
      "epoch": 2.6938947368421053,
      "grad_norm": 0.16231749951839447,
      "learning_rate": 5.2684757505773676e-05,
      "loss": 2.1191,
      "step": 3200
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.14835761487483978,
      "learning_rate": 4.5467667436489605e-05,
      "loss": 2.1131,
      "step": 3250
    },
    {
      "epoch": 2.7781052631578946,
      "grad_norm": 0.19667132198810577,
      "learning_rate": 3.825057736720555e-05,
      "loss": 2.1117,
      "step": 3300
    },
    {
      "epoch": 2.8202105263157895,
      "grad_norm": 0.1820823848247528,
      "learning_rate": 3.1033487297921476e-05,
      "loss": 2.1055,
      "step": 3350
    },
    {
      "epoch": 2.8623157894736844,
      "grad_norm": 0.13109838962554932,
      "learning_rate": 2.3816397228637414e-05,
      "loss": 2.1255,
      "step": 3400
    },
    {
      "epoch": 2.904421052631579,
      "grad_norm": 0.18997983634471893,
      "learning_rate": 1.6599307159353346e-05,
      "loss": 2.1419,
      "step": 3450
    },
    {
      "epoch": 2.9465263157894737,
      "grad_norm": 0.16854478418827057,
      "learning_rate": 9.382217090069284e-06,
      "loss": 2.1299,
      "step": 3500
    },
    {
      "epoch": 2.9886315789473685,
      "grad_norm": 0.16512055695056915,
      "learning_rate": 2.1651270207852194e-06,
      "loss": 2.0916,
      "step": 3550
    }
  ],
  "logging_steps": 50,
  "max_steps": 3564,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1345453891584e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
